{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning of Cohorts: publicidad y privacidad\n",
    "> En la actualidad se está dando una mayor prioridad al desarrollo de nuevas tecnologías que preserven la privacidad de usuario. Una de ellas es el federated learning. En este post voy a dar algunas pinceladas sobre lo que es, cual es su utilidad y porqué nos debería importar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha saltado la noticia de que [Google está proponiendo una solución al problema de las cookies](https://www.xataka.com/servicios/floc-alternativa-google-a-cookies-no-convence-duckduckgo-brave-se-han-pronunciado-van-a-bloquearlo) mediante algo llamado FloC o Federated Learning of Cohorts. Para algunos es una solución que preserva la privacidad del usuario mientras permite el rastreo, para otros es la peor solución que Google podría haber tomado. \n",
    "Algunas de las reacciones que podríamos tener son:\n",
    "\n",
    "[Espera, ¡eso de que nos rastreen es malo!](#id1)  \n",
    "[¿Fede…que?](#id2)  \n",
    "[¿Pero que pasa con MIS datos? ¿Y mi privacidad?](#id3)  \n",
    "[¿Y dónde están los PEROS?](#id4)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Espera, ¡eso de que nos rastreen es malo!__ <a name=\"id1\"></a>  \n",
    "Bueno, empecemos por como funcionan las _cookies_ de terceros que es lo que tenemos ahora. Las _cookies_ son eso que siempre aceptamos cuando abrimos una pagina web. Tras la aprobación [en Europa de la GDPR (General Data Protection Regulation)](https://eur-lex.europa.eu/eli/reg/2016/679/oj) empezó a aparecer en todos nuestro navegador un banner para recordarnos que cada vez que entramos en una web damos permisos para que nos rastreen. Y aunque nos pueda parecer algo engorroso, encuentro que es algo positivo para concienciarnos. De cierta forma acerca eso que sucede entre bambalinas a nuestra experiencia del día a día. Y si por un casual nos pica la curiosidad es posible ver la (en ocasiones) alarmante cantidad de rastreadores a los que damos permisos cuando damos a Aceptar.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Pero que es eso de las cookies? Las _cookies_ son un tipo de información que se almacena en el navegador y que cumple dos funciones. La primera y __muy útil es recordar accesos__ (evitándonos tener que estar constantemente introduciendo nuestro usuario y contraseña cada vez que usamos un servicio). La segunda y __más oscura, que empresas puedan recopilar nuestros datos__ de navegación para poder ofrecernos publicidad acorde a nuestro perfil [como nos explican en _Datanomics_](https://psiconomicon.github.io/blog/psicolog%C3%ADa/privacidad/datos/libro/2021/03/24/Datanomics.html). Lo cual presenta riesgos para nuestra privacidad y el aumento de nuestra vulnerabilidad frente a los spyware. Ante esto, se están desarrollando tecnologías como el cifrado homomórfico y el que hoy nos atañe, el federated learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __¿Fede…que?__<a name=\"id2\"></a>     \n",
    "El _[federated learning](https://en.wikipedia.org/wiki/Federated_learning)_ es una tecnología relativamente reciente (empezó a surgir en 2015) que tiene por __eje principal preservar la privacidad__ a la par que permite el procesado de datos. Hablando claro, el objetivo sería procesar la información sin que esta abandonara el dispositivo en el que se almacena. [El concepto en sí es contraintuituvo.](https://web.dev/floc/) ¿Trabajar con información sobre la que no tenemos acceso? Si, mediante aprendizaje automático. Para alejarnos un poco del ejemplo de la privacidad del usuario pondré un ejemplo a nivel empresarial, donde también existe interés en desarrollar estas técnicas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que somos una startup que quiere entrenar su algoritmo con los datos de diferentes empresas. Sin embargo, nosotros no queremos compartir con dicha startup ni con las otras nuestra base de datos ya que es nuestro ‘secreto comercial’. No queremos, ni podemos, compartir dicha información confidencial. ¿Podemos salir de ese callejón sin salida? Podríamos firmar un acuerdo de confidencialidad, pero siempre que compartes cierta información pierdes el control sobre la copia de la misma (exactamente el mismo problema que el de la piratería de música, películas y series). ¿Entonces…?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos en la misma situación que la del usuario medio, quiere preservar la privacidad de sus datos, pero a la par, obtener un servicio que requiere del uso de los mismos. Mediante ___federated learning_ lo que podemos hacer es enviar un modelo a los diferentes propietarios de los datos y agregar los resultados que estos nos envíen de vuelta__. De esta manera, __nadie tiene acceso a los datos a parte del dueño__ a la par que obtenemos el modelo entrenado que queríamos. Algo similar es lo que proponen hacer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, se están desarrollando tecnologías que buscan proteger la privcidad del usuario. Gigantes de internet como Google o Facebook están alentando el desarrollo de estas tecnologías. Por un lado, __lo podríamos considerar un lavado de imagen__, es tecnología que está siendo desarrollada con la privacidad como eje principal, una cuestión por la que son duramente criticados. Por otro lado, pese a que puede plantear problemas para sus modelos de negocio a largo plazo, no a corto. Como estamos viendo, el cambio que ellos proponen es seguir con el modelo de negocio de la publicidad tomando medidad que preserven la privacidad del usuario.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __¿Pero que pasa con MIS datos? ¿Y mi privacidad?__<a name=\"id3\"></a>    \n",
    "Ahora mismo has perdido el control sobre esos datos ya que empresas rastreadoras estan recopilando tus datos para generar un perfil, tu YO digital, y te/lo usan para lucrarse. Si te asalta la duda de _¿Porqué me deberia importar?_ Te remito a la entrada sobre _Datanomics_. La diferencia mediante Federated learning es que técnicamente __los datos del usuario siguen siendo privados ya que la información estaría a salvo dentro del dispositivo__ y el resultado sería ser asignado a una cohorte (imagínate una manda de cebras, los leones no pueden ir a por una porque el individuo se confunde con el todo).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __El sistema no es perfecto__, si alguien guarda la información cada vez que a uno le resignan de cohorte (o manada) al final se puede hacer un perfil individualizado, en otras palabras, desanonimizar los datos. Existe una métrica para saber cuanta privacidad se ‘pierde’ debido a estos intercambios conocidos como [privacidad diferencial](https://en.wikipedia.org/wiki/Differential_privacy). Para ser más precisos, $\\epsilon$_-privacidad diferencial_ para cuando los datos se comparten de forma intencionada y $\\delta$_-privacidad diferencial_ para la probabilidad de ‘fuga’ o robo de datos. Donde, llegados a cierto punto, la desanonimización es posible.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre esto es una carrera entre encriptación y desencriptación donde se pueden implantar estrategias para mitigar esta pérdida de $\\epsilon$_-privacidad diferencial_, a la par que se siguen investigado tecnologías para evitar dicha pérdida. Ninguna tecnología es perfecta, por lo que una vez hecha la ley, hecha la trampa.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __¿Y dónde están los Peros?__<a name=\"id4\"></a>    \n",
    "Eso depende de aquien le preguntes. Por un lado tenemos a _Apple_ cuya politica es respetar la privacidad del usuario dirá en todo. Recordemos que _Apple_ hace negocio vendiendo dispositivos (y accesiorios para esos dispositivos) mientras que los ingresos de Facebook, por ejemplo, proceden de los anucios, por lo que están pero que muy a favor del restreo. [Este conflicto de intereses y políticas entre los dos gigantes ha llevado a un choque entre ambos gigantes hace poco.](https://www.bbc.com/news/technology-56831241?xtor=AL-72-%5Bpartner%5D-%5Bbbc.news.twitter%5D-%5Bheadline%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D&at_medium=custom7&at_custom1=%5Bpost+type%5D&at_custom3=%40BBCTech&at_custom2=twitter&at_campaign=64&at_custom4=2BC5F6E8-A61E-11EB-8355-2EEC4744363C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como dije al inicio del post, para algunos [la opción que ha elegido Google es pésima](https://www.eff.org/deeplinks/2021/03/googles-floc-terrible-idea) y [animan a los usuarios a tratar de evitar ser participantes en las pruebas](https://www.muycomputer.com/2021/04/11/google-chrome-floc/) que están llevando a cabo para comprobar la viabilidad del proyecto. Al principio me daba la impresión al leer los titulares y algunas partes de los articulos que el problema residía en la tecnología empleada. En cambio, a medida que leía, iba cayendo en la cuenta de que __el problema reside en mismo seguimiento de los usuarios__. Aunque sea para proporcionar publicidad el rastreo es potencialmente peligroso [como comenté en aquí](https://psiconomicon.github.io/blog/psicolog%C3%ADa/privacidad/datos/libro/2021/04/14/Addiction_by_design.html), más allá de que el sistema no sea perfecto. __La posibilidad de crear perfiles individuales abre la puerta a la discriminación__. Por lo que aquí entramos en un debate entre el __idealismo__ (todo rastreo es peligroso), el __pragmatismo__ (existe un problema, es necesario mitigarlo) y la __ética__ (la privacidad del usuario es un derecho).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> twitter: https://twitter.com/Victoregb/status/1362357864195588096\n",
    "\n",
    "Personalmente encuentro que una posicion pragmatica es más realista para afrontar el problema y ponerle coto que tratar de cambiar la forma de actuar de millones de personas. Si tu argumento se aleja demasiado de la experiencia del dia a dia del ususario, lo más probable es que para ellos dicho argumento tenga poco peso. Es algo que estamos viendo con WhatsApp y sus cambios de condiciones, [hubo una gran migración a otros servicios](https://cincodias.elpais.com/cincodias/2021/01/20/lifestyle/1611130880_871395.html), pero aún está por ver que impacto real tiene.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Que pensáis de la implantación y desarrollo de este tipo de tecnologías para salvaguardar nuestra privacidad sin renunciar a los servicios? ¿Y vosotros que opináis? ¿Que pasos consideráis necesarios o que exigiríais para que se respete vuestra privacidad? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
